{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kohathyli/Chicago-Crime-Prediction/blob/main/pandas2vector.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Code that transforms a dataframe to vector format and vice versa\n",
        "\n",
        "Transform and reverse transform the data, allowing for preprocessing and postprocessing steps in pipelines. It provides functionality to handle missing values, encode categorical variables, and scale numeric variables."
      ],
      "metadata": {
        "id": "qXLsxNHalfrv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
        "from pandas.api.types import is_numeric_dtype"
      ],
      "metadata": {
        "id": "DwSsRb4Jni6S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DataTransformer:\n",
        "    \"\"\"\n",
        "    Class for transforming data for machine learning.\n",
        "\n",
        "    This class handles transformations like one-hot encoding for categorical data,\n",
        "    min-max scaling for numerical data, and handling missing data.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, variable_types):\n",
        "        \"\"\"Initialize the transformer with the variable types dictionary.\"\"\"\n",
        "        self.variable_types = variable_types\n",
        "        self.one_hot_encoders = {}\n",
        "        self.min_max_scalers = {}\n",
        "\n",
        "    def transform_dataframe(self, original_df):\n",
        "        \"\"\"\n",
        "        Transform the dataframe according to the variable types.\n",
        "\n",
        "        Categorical variables are one-hot encoded, numeric variables are min-max scaled,\n",
        "        and missing values are replaced with dummy variables.\n",
        "\n",
        "        Returns:\n",
        "        - The transformed dataframe.\n",
        "        - Dictionaries with fitted OneHotEncoders and MinMaxScalers for each column.\n",
        "        \"\"\"\n",
        "        df = original_df.copy()\n",
        "\n",
        "        for column, variable_type in self.variable_types.items():\n",
        "            if variable_type == 'categorical':\n",
        "                one_hot_encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
        "                df_encoded = pd.DataFrame(one_hot_encoder.fit_transform(df[[column]]))\n",
        "                df_encoded.columns = [f\"{column}_{cat}\" for cat in one_hot_encoder.categories_[0]]\n",
        "                df = pd.concat([df, df_encoded], axis=1)\n",
        "                df = df.drop(column, axis=1)\n",
        "                self.one_hot_encoders[column] = one_hot_encoder\n",
        "            elif variable_type == 'numeric' and is_numeric_dtype(df[column]):\n",
        "                min_max_scaler = MinMaxScaler()\n",
        "                non_na_rows = df[column].notna()\n",
        "                df.loc[non_na_rows, column] = min_max_scaler.fit_transform(df.loc[non_na_rows, [column]]).ravel()\n",
        "                self.min_max_scalers[column] = min_max_scaler\n",
        "\n",
        "        # Add missing indicators\n",
        "        df = self.add_missing_indicators(df)\n",
        "\n",
        "        return df, self.one_hot_encoders, self.min_max_scalers\n",
        "\n",
        "\n",
        "    def add_missing_indicators(self, df):\n",
        "        \"\"\"\n",
        "        Adds binary columns to the dataframe indicating the presence of missing values.\n",
        "\n",
        "        For each column in the dataframe, this function adds a corresponding column\n",
        "        with a binary indicator of whether the value in that row is missing (NaN).\n",
        "        These new columns are named 'missing_<column_name>' and are appended to the dataframe.\n",
        "\n",
        "        Args:\n",
        "            df (pd.DataFrame): The input pandas DataFrame.\n",
        "\n",
        "        Returns:\n",
        "            result (pd.DataFrame): The DataFrame with added missing value indicator columns.\n",
        "        \"\"\"\n",
        "\n",
        "        column_prefix = 'missing_'\n",
        "\n",
        "        #numeric_columns = [column for column, variable_type in self.variable_types.items() if variable_type == 'numeric']\n",
        "        #df_numeric = df.select_dtypes(include='number')\n",
        "\n",
        "        # Create DataFrame with indicator of missing values\n",
        "        #df_missing = pd.concat([df_numeric[c].isnull().astype(int) for c in df_numeric.columns], axis=1)\n",
        "        #df_missing.columns = [f'{column_prefix}{c}' for c in df_numeric.columns]\n",
        "\n",
        "        # Concatenate the original DataFrame with the missing indicator DataFrame\n",
        "        #result = pd.concat([df, df_missing], axis='columns')\n",
        "\n",
        "        #return result\n",
        "\n",
        "        result = df.copy()\n",
        "        for column in df.columns:\n",
        "            missing_col = f'{column_prefix}{column}'\n",
        "            result[missing_col] = df[column].isnull().astype(int)\n",
        "\n",
        "        return result\n",
        "\n",
        "    @staticmethod\n",
        "    def proba_to_onehot(proba):\n",
        "        \"\"\"Convert a vector of probabilities into a max-likelihood one-hot vector.\"\"\"\n",
        "        onehot = np.zeros_like(proba)\n",
        "        onehot[np.arange(len(proba)), np.argmax(proba, axis=1)] = 1\n",
        "        return onehot\n",
        "\n",
        "\n",
        "    def reverse_transform_dataframe(self, variable_types1, transformed_df):\n",
        "        \"\"\"\n",
        "        Reverse the transformations applied to the dataframe.\n",
        "\n",
        "        One-hot encoded categorical variables are decoded and min-max scaled numeric variables\n",
        "        are inverse scaled.\n",
        "\n",
        "        Returns the original dataframe.\n",
        "        \"\"\"\n",
        "        df = transformed_df.copy()\n",
        "\n",
        "        for column, variable_type in variable_types1.items():\n",
        "            if variable_type == 'categorical':\n",
        "                one_hot_encoder = self.one_hot_encoders[column]\n",
        "                original_cols = [col for col in df.columns if col.startswith(f\"{column}_\")]\n",
        "                df_proba = df[original_cols].values\n",
        "                onehot = self.proba_to_onehot(df_proba)\n",
        "                df_original = pd.DataFrame(one_hot_encoder.inverse_transform(onehot))\n",
        "                df_original.columns = [column]\n",
        "                df = pd.concat([df.drop(original_cols, axis=1), df_original], axis=1)\n",
        "            elif variable_type == 'numeric' and is_numeric_dtype(df[column]):\n",
        "                min_max_scaler = self.min_max_scalers[column]\n",
        "                non_na_rows = df[column].notna()\n",
        "                #df.loc[non_na_rows, column] = min_max_scaler.inverse_transform(df.loc[non_na_rows, [column]]).ravel()\n",
        "                #df.loc[non_na_rows, column] = min_max_scaler.inverse_transform(df.loc[non_na_rows, [column]]).ravel().reshape(-1, 1)\n",
        "                inverse_transformed = min_max_scaler.inverse_transform(df.loc[non_na_rows, [column]])\n",
        "                df.loc[non_na_rows, column] = inverse_transformed.flatten()\n",
        "\n",
        "        # Remove missing indicators\n",
        "        df = df.drop([col for col in df.columns if col.startswith('missing_')], axis=1)\n",
        "\n",
        "        return df\n"
      ],
      "metadata": {
        "id": "s1Myubs5o9Q5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import unittest\n",
        "\n",
        "class TestDataTransformer(unittest.TestCase):\n",
        "    def setUp(self):\n",
        "        self.variable_types = {\n",
        "            'age': 'numeric',\n",
        "            'gender': 'categorical',\n",
        "            'income': 'numeric'\n",
        "        }\n",
        "        self.transformer = DataTransformer(self.variable_types)\n",
        "        self.data = pd.DataFrame({\n",
        "            'age': [25, 30, 35, np.nan],\n",
        "            'gender': ['male', 'female', 'male', 'female'],\n",
        "            'income': [50000.0, 60000.0, 70000.0, 80000.0]\n",
        "        })\n",
        "\n",
        "    def test_add_missing_indicators(self):\n",
        "        df = pd.DataFrame({\n",
        "            'age': [25, 30, np.nan, 35],\n",
        "            'gender': ['male', 'female', None, 'male'],\n",
        "        })\n",
        "\n",
        "        transformed_df = self.transformer.add_missing_indicators(df)\n",
        "\n",
        "        # Check that the output DataFrame has twice as many columns as the input DataFrame\n",
        "        self.assertEqual(transformed_df.shape[1], 2 * df.shape[1])\n",
        "\n",
        "        # Check that the output DataFrame contains all of the columns of the input DataFrame\n",
        "        self.assertTrue(set(df.columns).issubset(set(transformed_df.columns)))\n",
        "\n",
        "        # Check that the added columns in the output DataFrame start with 'missing_'\n",
        "        missing_cols = [col for col in transformed_df.columns if col.startswith('missing_')]\n",
        "        self.assertEqual(len(missing_cols), df.shape[1])\n",
        "\n",
        "        # Check that 'missing_' columns contain only 0s and 1s\n",
        "        for col in missing_cols:\n",
        "            self.assertTrue(set(transformed_df[col].unique()).issubset({0, 1}))\n",
        "\n",
        "        # Check that the number of 1s in 'missing_' columns matches the number of NaN values in the original DataFrame\n",
        "        for original_col in df.columns:\n",
        "            missing_col = f'missing_{original_col}'\n",
        "            self.assertEqual(transformed_df[missing_col].sum(), df[original_col].isnull().sum())\n",
        "\n",
        "\n",
        "    def test_transform_dataframe(self):\n",
        "\n",
        "        transformed_df, _, _ = self.transformer.transform_dataframe(self.data)\n",
        "\n",
        "        # Check that original DataFrame has been transformed properly\n",
        "        self.assertNotIn('gender', transformed_df.columns)\n",
        "        self.assertIn('gender_male', transformed_df.columns)\n",
        "        self.assertIn('gender_female', transformed_df.columns)\n",
        "\n",
        "        # Check that missing values have been handled correctly\n",
        "        self.assertEqual(transformed_df.loc[3, 'missing_age'], 1)\n",
        "        self.assertEqual(transformed_df.loc[0, 'missing_age'], 0)\n",
        "\n",
        "        # Check that numeric columns have been scaled correctly\n",
        "        self.assertEqual(transformed_df.loc[0, 'age'], 0)\n",
        "        self.assertEqual(transformed_df.loc[1, 'age'], 0.5)\n",
        "        self.assertEqual(transformed_df.loc[2, 'age'], 1)\n",
        "        self.assertTrue(np.isnan(transformed_df.loc[3, 'age']))\n",
        "\n",
        "\n",
        "    def test_proba_to_onehot(self):\n",
        "        proba = np.array([[0.1, 0.9], [0.7, 0.3]])\n",
        "        expected_onehot = np.array([[0, 1], [1, 0]])\n",
        "\n",
        "        np.testing.assert_array_equal(self.transformer.proba_to_onehot(proba), expected_onehot)\n",
        "\n",
        "    def test_reverse_transform_dataframe(self):\n",
        "        transformed_df, _, _ = self.transformer.transform_dataframe(self.data)\n",
        "        reversed_df = self.transformer.reverse_transform_dataframe(self.variable_types, transformed_df)\n",
        "\n",
        "        # Check that DataFrame has been reversed correctly\n",
        "        pd.testing.assert_frame_equal(reversed_df, self.data, check_like=True)\n",
        "\n",
        "        # Check that the missing data has been reversed correctly\n",
        "        self.assertTrue(pd.isnull(reversed_df.loc[3, 'age']))\n",
        "\n",
        "        # Check that the numeric scaling has been reversed correctly\n",
        "        self.assertTrue('age' in reversed_df.columns)\n",
        "        self.assertTrue('income' in reversed_df.columns)\n",
        "        self.assertListEqual(list(self.data['age'].dropna()), list(reversed_df['age'].dropna()))\n",
        "        self.assertListEqual(list(self.data['income']), list(reversed_df['income']))\n",
        "\n",
        "        # Check that the categorical encoding has been reversed correctly\n",
        "        self.assertTrue('gender' in reversed_df.columns)\n",
        "        self.assertListEqual(list(self.data['gender']), list(reversed_df['gender']))\n",
        "\n",
        "def run_tests(test_class):\n",
        "    suite = unittest.TestLoader().loadTestsFromTestCase(test_class)\n",
        "    runner = unittest.TextTestRunner()\n",
        "    runner.run(suite)\n"
      ],
      "metadata": {
        "id": "PXzlb49JnaLq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "  run_tests(TestDataTransformer)"
      ],
      "metadata": {
        "id": "Fa1q7NuXV0GS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}