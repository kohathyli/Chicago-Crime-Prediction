{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kohathyli/Chicago-Crime-Prediction/blob/main/autoencoder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EgC-DNoNxTC1"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.layers import Input, Dense, BatchNormalization\n",
        "from keras.models import Model\n",
        "from kerastuner.tuners import RandomSearch, BayesianOptimization\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "\n",
        "class AutoencoderModel:\n",
        "    def __init__(self):\n",
        "        self.INPUT_SHAPE = None\n",
        "        self.D = 2\n",
        "        self.TEST_SIZE = 0.2\n",
        "        self.RANDOM_STATE = 42\n",
        "        self.SEED = 42\n",
        "        self.MAX_TRIALS = 20\n",
        "        self.EXECUTIONS_PER_TRIAL = 1\n",
        "        self.EPOCHS = 50\n",
        "\n",
        "    def split_train_test(self, df):\n",
        "        # df = df.fillna(0.0)\n",
        "        X_train, X_test = train_test_split(df.copy(), test_size=self.TEST_SIZE, random_state=self.RANDOM_STATE)\n",
        "        # X_train = X_train.values.astype('float32')\n",
        "        # X_test = X_test.values.astype('float32')\n",
        "        # X_train = X_train.reshape((len(X_train), np.prod(X_train.shape[1:])))\n",
        "        # X_test = X_test.reshape((len(X_test), np.prod(X_test.shape[1:])))\n",
        "        self.INPUT_SHAPE = X_train.shape[1:]\n",
        "        return X_train.dropna(), X_test.dropna()\n",
        "\n",
        "    @staticmethod\n",
        "    def masked_mse(y_true, y_pred):\n",
        "        mask = tf.math.is_finite(y_true)\n",
        "        y_t = tf.where(tf.math.is_finite(y_true), y_true, 0.0)\n",
        "        y_p = tf.where(tf.math.is_finite(y_pred), y_pred, 0.0)\n",
        "        mse = tf.keras.losses.MeanSquaredError(reduction=tf.keras.losses.Reduction.NONE)\n",
        "        return tf.reduce_mean(mse(y_t*tf.cast(mask, y_t.dtype), y_p*tf.cast(mask, y_p.dtype)))\n",
        "\n",
        "\n",
        "\n",
        "    def build_encoder(self, hp):\n",
        "        inputs = Input(shape=self.INPUT_SHAPE)\n",
        "        x = Dense(units=hp.Int('encoder_units_1', min_value=16, max_value=256, step=16), activation='relu')(inputs)\n",
        "        x = BatchNormalization()(x)\n",
        "        x = Dense(units=hp.Int('encoder_units_2', min_value=16, max_value=128, step=16), activation='relu')(x)\n",
        "        x = BatchNormalization()(x)\n",
        "        latent_space = Dense(units=self.D, activation='relu')(x)\n",
        "        return Model(inputs, latent_space)\n",
        "\n",
        "    def build_decoder(self, hp):\n",
        "        decoder_inputs = Input(shape=(self.D,))\n",
        "        x = Dense(units=hp.Int('decoder_units_1', min_value=16, max_value=256, step=16), activation='relu')(decoder_inputs)\n",
        "        x = BatchNormalization()(x)\n",
        "        x = Dense(units=hp.Int('decoder_units_2', min_value=16, max_value=256, step=16), activation='relu')(x)\n",
        "        x = BatchNormalization()(x)\n",
        "        outputs = Dense(units=self.INPUT_SHAPE[0], activation='linear')(x)\n",
        "        return Model(decoder_inputs, outputs)\n",
        "\n",
        "    def build_autoencoder(self, hp):\n",
        "        learning_rate = hp.Choice('learning_rate', values=[1.0, 1e-1, 1e-2, 1e-3, 1e-4, 1e-5])\n",
        "        batch_size = hp.Int('batch_size', min_value=16, max_value=256, step=16)\n",
        "        autoencoder_input = Input(shape=self.INPUT_SHAPE)\n",
        "        encoder_output = self.build_encoder(hp)(autoencoder_input)\n",
        "        decoder_output = self.build_decoder(hp)(encoder_output)\n",
        "        autoencoder = Model(autoencoder_input, decoder_output)\n",
        "        autoencoder.compile(optimizer=keras.optimizers.Adam(learning_rate=learning_rate), loss='mse')\n",
        "        # autoencoder.summary()\n",
        "        # autoencoder.save(f'{self.DIRECTORY}/autoencoder_model.h5\n",
        "        return autoencoder\n",
        "\n",
        "    def define_tuner(self):\n",
        "        tuner = BayesianOptimization(\n",
        "            self.build_autoencoder,\n",
        "            objective='val_loss',\n",
        "            max_trials=self.MAX_TRIALS,\n",
        "            executions_per_trial=self.EXECUTIONS_PER_TRIAL,\n",
        "            # directory=self.DIRECTORY,\n",
        "            # project_name=self.PROJECT_NAME,\n",
        "            # overwrite=self.OVERWRITE,\n",
        "            seed=self.SEED\n",
        "            )\n",
        "        return tuner\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Autoencoder(nn.Module):\n",
        "    def __init__(self,D_in,H=50,H2=12,latent_dim=3):\n",
        "\n",
        "        #Encoder\n",
        "        super(Autoencoder,self).__init__()\n",
        "        self.linear1=nn.Linear(D_in,H)\n",
        "        self.lin_bn1 = nn.BatchNorm1d(num_features=H)\n",
        "        self.linear2=nn.Linear(H,H2)\n",
        "        self.lin_bn2 = nn.BatchNorm1d(num_features=H2)\n",
        "        self.linear3=nn.Linear(H2,H2)\n",
        "        self.lin_bn3 = nn.BatchNorm1d(num_features=H2)\n",
        "\n",
        "        # Latent vectors mu and sigma\n",
        "        self.fc1 = nn.Linear(H2, latent_dim)\n",
        "        self.bn1 = nn.BatchNorm1d(num_features=latent_dim)\n",
        "        self.fc21 = nn.Linear(latent_dim, latent_dim)\n",
        "        self.fc22 = nn.Linear(latent_dim, latent_dim)\n",
        "\n",
        "        # Sampling vector\n",
        "        self.fc3 = nn.Linear(latent_dim, latent_dim)\n",
        "        self.fc_bn3 = nn.BatchNorm1d(latent_dim)\n",
        "        self.fc4 = nn.Linear(latent_dim, H2)\n",
        "        self.fc_bn4 = nn.BatchNorm1d(H2)\n",
        "\n",
        "        # Decoder\n",
        "        self.linear4=nn.Linear(H2,H2)\n",
        "        self.lin_bn4 = nn.BatchNorm1d(num_features=H2)\n",
        "        self.linear5=nn.Linear(H2,H)\n",
        "        self.lin_bn5 = nn.BatchNorm1d(num_features=H)\n",
        "        self.linear6=nn.Linear(H,D_in)\n",
        "        self.lin_bn6 = nn.BatchNorm1d(num_features=D_in)\n",
        "\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def encode(self, x):\n",
        "        lin1 = self.relu(self.lin_bn1(self.linear1(x)))\n",
        "        lin2 = self.relu(self.lin_bn2(self.linear2(lin1)))\n",
        "        lin3 = self.relu(self.lin_bn3(self.linear3(lin2)))\n",
        "\n",
        "        fc1 = F.relu(self.bn1(self.fc1(lin3)))\n",
        "\n",
        "        r1 = self.fc21(fc1)\n",
        "        r2 = self.fc22(fc1)\n",
        "\n",
        "        return r1, r2\n",
        "\n",
        "    def reparameterize(self, mu, logvar):\n",
        "        if self.training:\n",
        "            std = logvar.mul(0.5).exp_()\n",
        "            eps = Variable(std.data.new(std.size()).normal_())\n",
        "            return eps.mul(std).add_(mu)\n",
        "        else:\n",
        "            return mu\n",
        "\n",
        "    def decode(self, z):\n",
        "        fc3 = self.relu(self.fc_bn3(self.fc3(z)))\n",
        "        fc4 = self.relu(self.fc_bn4(self.fc4(fc3)))\n",
        "\n",
        "        lin4 = self.relu(self.lin_bn4(self.linear4(fc4)))\n",
        "        lin5 = self.relu(self.lin_bn5(self.linear5(lin4)))\n",
        "        return self.lin_bn6(self.linear6(lin5))\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        mu, logvar = self.encode(x)\n",
        "        z = self.reparameterize(mu, logvar)\n",
        "        return self.decode(z), mu, logvar\n",
        "\n"
      ],
      "metadata": {
        "id": "6IjWU8YuoZoP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class customLoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(customLoss, self).__init__()\n",
        "        self.mse_loss = nn.MSELoss(reduction=\"sum\")\n",
        "\n",
        "    def forward(self, x_recon, x, mu, logvar):\n",
        "        loss_MSE = self.mse_loss(x_recon, x)\n",
        "        loss_KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
        "\n",
        "        return loss_MSE + loss_KLD"
      ],
      "metadata": {
        "id": "tz3NN00Tn-Uo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "edJpFXRfoEZl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}